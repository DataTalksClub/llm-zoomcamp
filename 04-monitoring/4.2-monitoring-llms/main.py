import logging
from tqdm.auto import tqdm
from sklearn.metrics.pairwise import cosine_similarity
from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline

from documents_database import (
    setup_es_client_and_index,
    dump_doc_embeddings_to_db,
    extend_ground_truth_dataset,
    elastic_search_fields
)

from utils.llm_utils import ask_llm
from utils.postgres import (
    POSTGRES_DB_PARAMS,
    create_monitoring_db,
    create_metrics_table,
    save_metrics_to_db
)

POSTGRES_DB_PARAMS["dbname"] = "ground_truth_monitoring"
create_monitoring_db(POSTGRES_DB_PARAMS)
create_metrics_table(POSTGRES_DB_PARAMS)


logging.basicConfig()
logging.getLogger().setLevel(logging.INFO)

ES_INDEX_NAME = "course_questions"


def compute_cosine_similarity(result: list, index_name: str):
    logging.info(
        "Computing cosine similarity between text and llm answer vector")
    for entry in tqdm(result):
        cosine_similarity_value = cosine_similarity(
            [entry["_source"]["text_vector"]],
            [entry["_source"]["llm_answer_vector"]]
        )[0][0]
        save_metrics_to_db(POSTGRES_DB_PARAMS,
                           text_id=entry["_source"]['id'], cosine_similarity=cosine_similarity_value)


def compute_sentiment(result: list, hugginface_model_path: str, index_name: str):
    logging.info(
        f"Downloading {hugginface_model_path} from Huggingface for classifying sentiment.")
    tokenizer = AutoTokenizer.from_pretrained(hugginface_model_path)
    model = AutoModelForSequenceClassification.from_pretrained(
        hugginface_model_path)
    pipeline = TextClassificationPipeline(
        model=model, tokenizer=tokenizer, truncation=True)

    logging.info("Detecting negative sentiment in llm answer.")
    for entry in tqdm(result):
        sentiment = pipeline(entry["_source"]["llm_answer"])[0]["label"]
        negative = True if sentiment == "NEG" else False
        save_metrics_to_db(POSTGRES_DB_PARAMS,
                           text_id=entry["_source"]['id'],  negative_answer=negative)


def compute_llm_as_a_judge(result: list, openai_model_name: str, index_name: str):
    logging.info(
        "Using LLM as a judge to assess suitability of llm answer for the corresponding question.")
    for entry in tqdm(result):
        prompt = f"""
            Please assess if the answer generated by an LLM "{entry['_source']['llm_answer']}" is suitable to answer the given question: "{entry['_source']['question']}"

            Use the following categories to judge the quality:
            good if the llm_answer is suitable to answer the question
            ok if the llm_answer is partly suitable to answer the question
            bad if the llm_answer is not suitable to answer the question
            Return only one category.
        """
        result = ask_llm(openai_model_name, [
                         {"role": "user", "content": prompt}], mock_answer=False).lower()
        judge = result if result in ["good", "ok", "bad"] else "unknown"
        save_metrics_to_db(POSTGRES_DB_PARAMS,
                           text_id=entry["_source"]['id'], llm_judge=judge)


if __name__ == "__main__":
    es_client = setup_es_client_and_index(index_name=ES_INDEX_NAME)
    # dump_doc_embeddings_to_db(es_client=es_client, index_name=ES_INDEX_NAME)
    # extend_ground_truth_dataset(es_client=es_client, index_name=ES_INDEX_NAME)

    result = elastic_search_fields(es_client=es_client, index_name=ES_INDEX_NAME, search_query={
        "query": {
            "bool": {
                "must": [
                    {"exists": {"field": "text_vector"}},
                    {"exists": {"field": "llm_answer_vector"}}
                ]
            }
        }
    })
    logging.info(f'Found {len(result)} results.')
    compute_cosine_similarity(result, index_name=ES_INDEX_NAME)
    compute_sentiment(
        result, hugginface_model_path="finiteautomata/bertweet-base-sentiment-analysis", index_name=ES_INDEX_NAME)
    compute_llm_as_a_judge(
        result, openai_model_name="gpt-3.5-turbo-0125", index_name=ES_INDEX_NAME)
