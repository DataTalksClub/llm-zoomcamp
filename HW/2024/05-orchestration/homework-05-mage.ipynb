{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b599e314-da15-4ab9-960e-6ad422ed4f37",
   "metadata": {},
   "source": [
    "Наші документи з поширеними запитаннями змінюються з часом: студенти додають нові записи та редагують існуючі. Нам потрібно підтримувати наш індекс синхронізованим.\n",
    "Існує два способи зробити це:\n",
    "Інкрементне: ви оновлюєте лише ті записи, які були змінені, створені або видалені\n",
    "Повне оновлення: ви створюєте весь індекс з нуля\n",
    "У цьому домашньому завданні ми розглянемо повне оновлення.\n",
    "Ми будемо запускати наш конвеєр індексування щодня і створювати індекс search кожного разу, коли ми його запускаємо.\n",
    "\n",
    "Для цього ми створили два документи з поширеними запитаннями для LLM Zoomcamp:\n",
    "* [версія 1](https://docs.google.com/document/d/1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E/edit)\n",
    "* [версія 2](https://docs.google.com/document/d/1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0/edit)\n",
    "\n",
    "Спочатку ми запустимо наш конвеєр поглинання з версією 1, а потім з версією 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16594035-3cae-4853-99c0-646dc568df73",
   "metadata": {},
   "source": [
    "### Q1. Running Mage\n",
    "Clone the same repo we used in the module and run mage:\n",
    "\n",
    "```git clone https://github.com/mage-ai/rag-project```\n",
    "Add the following libraries to the requirements document:\n",
    "```python\n",
    "python-docx\n",
    "elasticsearch\n",
    "```\n",
    "Make sure you use the latest version of mage:\n",
    "```bash\n",
    "docker pull mageai/mageai:llm\n",
    "```\n",
    "Start it:\n",
    "```\n",
    "./scripts/start.sh\n",
    "```\n",
    "Now mage is running on [http://localhost:6789/](http://localhost:6789/)\n",
    "\n",
    "What's the version of mage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e19a3e-5e9d-4a55-99e7-4b97e79aac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: v0.9.72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bee723-72b2-45f3-a67d-760a85af69a6",
   "metadata": {},
   "source": [
    "### Creating a RAG pipeline\n",
    "Create a RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc24d9-582a-4cdf-b76c-b286212353cd",
   "metadata": {},
   "source": [
    "### Q2. Reading the documents\n",
    "Тепер ми можемо поглинати документи. Створіть власний блок поглинання коду\n",
    "\n",
    "Давайте почитаємо документи. Ми будемо використовувати той самий код, який ми використовували для розбору FAQ: [parse-faq-llm.ipynb](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/cohorts/2024/05-orchestration/parse-faq-llm.ipynb)\n",
    "\n",
    "Використовуйте наступний документ_id: ```1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E```\n",
    "\n",
    "Який ідентифікатор документа [LLM FAQ version 1](https://docs.google.com/document/d/1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E/edit)\n",
    "\n",
    "Скопіюйте код в редактор. Скільки документів FAQ ми опрацювали?\n",
    "\n",
    "* 1\n",
    "* 2\n",
    "* 3\n",
    "* 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec67f7b-a8b5-4fcb-b0ac-aa880328fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fec5a5-1397-47c8-b0be-904b6bb7e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code for Mage Ingest\n",
    "import io\n",
    "import requests\n",
    "import docx\n",
    "\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "@data_loader\n",
    "def load_data(*args, **kwargs):\n",
    "    def clean_line(line):\n",
    "        line = line.strip()\n",
    "        line = line.strip('\\uFEFF')\n",
    "        return line\n",
    "\n",
    "    def read_faq(file_id):\n",
    "        url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with io.BytesIO(response.content) as f_in:\n",
    "            doc = docx.Document(f_in)\n",
    "\n",
    "        questions = []\n",
    "\n",
    "        question_heading_style = 'heading 2'\n",
    "        section_heading_style = 'heading 1'\n",
    "        \n",
    "        heading_id = ''\n",
    "        section_title = ''\n",
    "        question_title = ''\n",
    "        answer_text_so_far = ''\n",
    "        \n",
    "        for p in doc.paragraphs:\n",
    "            style = p.style.name.lower()\n",
    "            p_text = clean_line(p.text)\n",
    "        \n",
    "            if len(p_text) == 0:\n",
    "                continue\n",
    "        \n",
    "            if style == section_heading_style:\n",
    "                section_title = p_text\n",
    "                continue\n",
    "        \n",
    "            if style == question_heading_style:\n",
    "                answer_text_so_far = answer_text_so_far.strip()\n",
    "                if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                    questions.append({\n",
    "                        'text': answer_text_so_far,\n",
    "                        'section': section_title,\n",
    "                        'question': question_title,\n",
    "                    })\n",
    "                    answer_text_so_far = ''\n",
    "        \n",
    "                question_title = p_text\n",
    "                continue\n",
    "            \n",
    "            answer_text_so_far += '\\n' + p_text\n",
    "        \n",
    "        answer_text_so_far = answer_text_so_far.strip()\n",
    "        if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "            questions.append({\n",
    "                'text': answer_text_so_far,\n",
    "                'section': section_title,\n",
    "                'question': question_title,\n",
    "            })\n",
    "\n",
    "        return questions\n",
    "\n",
    "    faq_documents = {\n",
    "        #'llm-zoomcamp': '1m2KexowAXTmexfC5rVTCSnaShvdUQ8Ag2IEiwBDHxN0',\n",
    "        # Version 1\n",
    "        #'llm-zoomcamp': '1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E',\n",
    "        # Version 2\n",
    "        'llm-zoomcamp': '1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0',\n",
    "    }\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course, file_id in faq_documents.items():\n",
    "        print(course)\n",
    "        course_documents = read_faq(file_id)\n",
    "        documents.append({'course': course, 'documents': course_documents})\n",
    "    \n",
    "    return documents\n",
    "    \n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164fdb1-22eb-4340-a7bc-4866d5dc8e86",
   "metadata": {},
   "source": [
    "### Q3. Chunking\n",
    "Нам не потрібно робити ніякого дроблення, тому що наші документи вже мають чітко визначені межі. Тож нам просто потрібно повернути документи без будь-яких змін.\n",
    "\n",
    "Тож давайте перейдемо до частини трансформації і додамо кастомний блок розбиття коду на частини:\n",
    "```python\n",
    "documents = []\n",
    "\n",
    "for doc in data['documents']:\n",
    "    doc['course'] = data['course']\n",
    "    # previously we used just \"id\" for document ID\n",
    "    doc['document_id'] = generate_document_id(doc)\n",
    "    documents.append(doc)\n",
    "\n",
    "print(len(documents))\n",
    "\n",
    "return documents\n",
    "```\n",
    "Where data is the input parameter to the transformer.\n",
    "\n",
    "And the generate_document_id is defined in the same way as in module 4:\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id\n",
    "```\n",
    "Note: if instead of a single dictionary you get a list, add a for loop:\n",
    "```\n",
    "for course_dict in data:\n",
    "    ...\n",
    "```\n",
    "You can check the type of data with this code:\n",
    "\n",
    "```print(type(data))```\n",
    "\n",
    "How many documents (chunks) do we have in the output?\n",
    "\n",
    "* 66\n",
    "* 76\n",
    "* 86\n",
    "* 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b4cc9-9528-4654-b0e8-50a73df82746",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a2514-acf5-4f3c-ab15-d34766506b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code for Mage Transform --> Chunking\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Template code for a transformer block.\n",
    "\n",
    "    Add more parameters to this function if this block has multiple parent blocks.\n",
    "    There should be one parameter for each output variable from each parent block.\n",
    "\n",
    "    Args:\n",
    "        data: The output from the upstream parent block\n",
    "        args: The output from any additional upstream blocks (if applicable)\n",
    "\n",
    "    Returns:\n",
    "        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n",
    "    \"\"\"\n",
    "    # Specify your transformation logic here\n",
    "    import hashlib\n",
    "    print(type(data))\n",
    "    \n",
    "    def generate_document_id(doc):\n",
    "        combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "        hash_object = hashlib.md5(combined.encode())\n",
    "        hash_hex = hash_object.hexdigest()\n",
    "        document_id = hash_hex[:8]\n",
    "        return document_id\n",
    "        \n",
    "    documents = []\n",
    "\n",
    "    for doc in data['documents']:\n",
    "        doc['course'] = data['course']\n",
    "        # previously we used just \"id\" for document ID\n",
    "        doc['document_id'] = generate_document_id(doc)\n",
    "        documents.append(doc)\n",
    "\n",
    "    print(len(documents))\n",
    "\n",
    "    return documents\n",
    "\n",
    "    #return data\n",
    "\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81005dac-8b99-4ec0-9d1c-aec31b167ea7",
   "metadata": {},
   "source": [
    "### Токенізація та вбудовування\n",
    "Нам не знадобиться токенізація, тому ми пропустимо цей крок.\n",
    "\n",
    "Наразі токенізація потрібна в mage, тому ми можемо створити фіктивний блок коду:\n",
    "\n",
    "Створіть кастомний блок коду, але не змінюйте його.\n",
    "\n",
    "Оскільки ми будемо використовувати текстовий пошук, нам також не потрібні вбудовування, тому ми пропустимо цей крок.\n",
    "\n",
    "Якщо ви плануєте використовувати трансформатори речень (з модуля 3), то вам не знадобиться токенізація, але вам знадобляться вбудовування (хоча і не для цієї домашньої роботи)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e2687-8bd5-4de0-866d-96f422063f12",
   "metadata": {},
   "source": [
    "### Q4. Export\n",
    "Тепер ми готові проіндексувати дані за допомогою elasticsearch. Для цього ми скористаємося частиною конвеєра Експорт\n",
    "\n",
    "* Перейдіть до частини Експорт\n",
    "* Виберіть векторні бази даних -> Elasticsearch\n",
    "* Відкрийте код для редагування\n",
    "Оскільки ми будемо використовувати не векторний пошук, а звичайний текстовий, нам потрібно відкоригувати код.\n",
    "\n",
    "\n",
    "По-перше, змінимо рядок, де ми зчитуємо ім'я індексу:\n",
    "\n",
    "```index_name = kwargs.get('index_name', 'documents')```\n",
    "\n",
    "To ```index_name_prefix``` - we will parametrize it with the day and time we run the pipeline\n",
    "```python\n",
    "from datetime import datetime\n",
    "\n",
    "index_name_prefix = kwargs.get('index_name', 'documents')\n",
    "current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n",
    "index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "print(\"index name:\", index_name)\n",
    "```\n",
    "Нам потрібно буде зберегти ім'я в глобальній змінній, щоб воно було доступне в інших блоках коду\n",
    "```python\n",
    "from mage_ai.data_preparation.variable_manager import set_global_variable\n",
    "\n",
    "set_global_variable('YOUR_PIPELINE_NAME', 'index_name', index_name)\n",
    "```\n",
    "Де ім'я вашого конвеєра - це ім'я конвеєра, наприклад, transcendent_nexus (замініть пробіл на підкреслення _)\n",
    "\n",
    "Замініть налаштування індексу на ті, які ми використовували раніше:\n",
    "```python\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": number_of_shards,\n",
    "        \"number_of_replicas\": number_of_replicas\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"document_id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "Remove the embeddings line:\n",
    "```python\n",
    "if isinstance(document[vector_column_name], np.ndarray):\n",
    "    document[vector_column_name] = document[vector_column_name].tolist()\n",
    "```\n",
    "At the end (outside of the indexing for loop), print the last document:\n",
    "```python\n",
    "print(document)\n",
    "```\n",
    "Тепер виконайте блок.\n",
    "Який останній ідентифікатор документа?\n",
    "Також зверніть увагу на назву індексу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2d7a8-528c-41f9-9110-451a6339ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code for Mage Export --> Vector Database --> Elasticsearch\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from datetime import datetime\n",
    "from mage_ai.data_preparation.variable_manager import set_global_variable\n",
    "\n",
    "if 'data_exporter' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_exporter\n",
    "\n",
    "\n",
    "@data_exporter\n",
    "def elasticsearch(\n",
    "    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports document data to an Elasticsearch database.\n",
    "    \"\"\"\n",
    "\n",
    "    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n",
    "    #index_name = kwargs.get('index_name', 'documents')\n",
    "\n",
    "    index_name_prefix = kwargs.get('index_name', 'documents')\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "    print(\"index name:\", index_name)\n",
    "\n",
    "    set_global_variable('luminous_radiance', 'index_name', index_name)\n",
    "\n",
    "    number_of_shards = kwargs.get('number_of_shards', 1)\n",
    "    number_of_replicas = kwargs.get('number_of_replicas', 0)\n",
    "    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n",
    "\n",
    "    dimensions = kwargs.get('dimensions')\n",
    "    if dimensions is None and len(documents) > 0:\n",
    "        document = documents[0]\n",
    "        dimensions = len(document.get(vector_column_name) or [])\n",
    "\n",
    "    es_client = Elasticsearch(connection_string)\n",
    "\n",
    "    print(f'Connecting to Elasticsearch at {connection_string}')\n",
    "\n",
    "    # index_settings = dict(\n",
    "    #    settings=dict(\n",
    "    #        number_of_shards=number_of_shards,\n",
    "    #        number_of_replicas=number_of_replicas,\n",
    "    #    ),\n",
    "    #    mappings=dict(\n",
    "    #        properties=dict(\n",
    "    #            chunk=dict(type='text'),\n",
    "    #            document_id=dict(type='text'),\n",
    "    #            embedding=dict(type='dense_vector', dims=dimensions),\n",
    "    #        ),\n",
    "    #    ),\n",
    "    # )\n",
    "\n",
    "    index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": number_of_shards,\n",
    "        \"number_of_replicas\": number_of_replicas\n",
    "        },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"document_id\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if not es_client.indices.exists(index=index_name):\n",
    "        es_client.indices.create(index=index_name)\n",
    "        print('Index created with properties:', index_settings)\n",
    "        print('Embedding dimensions:', dimensions)\n",
    "\n",
    "    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n",
    "    for document in documents:\n",
    "        print(f'Indexing document {document[\"document_id\"]}')\n",
    "\n",
    "        # if isinstance(document[vector_column_name], np.ndarray):\n",
    "        #     document[vector_column_name] = document[vector_column_name].tolist()\n",
    "\n",
    "        es_client.index(index=index_name, document=document)\n",
    "    \n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25168bad-6806-495c-bb02-2e5448a7aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071f5ca-95ee-4686-ae82-91508d11216f",
   "metadata": {},
   "source": [
    "### Q1 - Q4 всі виконані в Mage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca65c76-c6e3-4bf3-8584-b3cfe6148606",
   "metadata": {},
   "source": [
    "### Q5 - Q6 виконано у Jupyter Notebook, оскільки не вдалося знайти функцію текстового пошукового запиту у Mage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310e2f6-f35c-459a-9f3c-94d96e8551ef",
   "metadata": {},
   "source": [
    "### Q5. Testing the retrieval\n",
    "Тепер давайте протестуємо пошук:\n",
    "* Для цього скористайтеся блокнотом mage або jupyter.\n",
    "* Давайте використаємо наступний запит: \"Коли наступна когорта?\"\n",
    "* Який ідентифікатор найкращого результату?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 1,
>>>>>>> 20e10198394f6f3ac9556dd4d10ea3f06b59d1cf
   "id": "c31d51b6-03a1-46ba-80bd-a382be24c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 2,
>>>>>>> 20e10198394f6f3ac9556dd4d10ea3f06b59d1cf
   "id": "d1456fd3-0d11-4a28-afd4-fa0d0098fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 3,
>>>>>>> 20e10198394f6f3ac9556dd4d10ea3f06b59d1cf
   "id": "360f1d91-7591-4d75-b17d-033e9e630123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, index_name):\n",
    "    search_query = {\n",
    "        \"size\": 1,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                # \"filter\": {\n",
    "                #     \"term\": {\n",
    "                #         \"course\": course\n",
    "                #     }\n",
    "                # }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ec66b-5740-441d-82ce-150406472512",
   "metadata": {},
   "source": [
    "## * Index name for version 1 document: ```documents_20240820_123728```\n",
    "* Index name for version 2 document: ```documents_20240820_201738```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d689065-2603-411b-8b28-14760eefa327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bober\\AppData\\Local\\Temp\\ipykernel_19116\\3842782351.py:22: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es_client.search(index=index_name, body=search_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = elastic_search(\n",
    "    query=\"When is the next cohort?\",\n",
    "    index_name=\"documents_20240820_123728\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93f011-bfa3-4ac8-9e8d-a3d14867c4c9",
   "metadata": {},
   "source": [
    "### Q6. Reindexing\n",
    "Наш документ FAQ змінюється: щодня учасники курсу додають нові записи або покращують вже існуючі.\n",
    "\n",
    "Уявіть, що минув певний час і документ змінився. На цей випадок у нас є інша версія документа FAQ: version 2.\n",
    "\n",
    "Ідентифікатор цього документа ```1T3MdwUvqCL3jrh3d3VCXQ8xE0UqRzI3bfgpfBq3ZWG0.```\n",
    "\n",
    "Повторно виконаємо весь конвеєр з оновленими даними.\n",
    "\n",
    "Для цього ж запиту \"When is the next cohort?\". Який ідентифікатор найкращого результату?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a917d61b-7d00-4950-baf5-b0e71851122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bober\\AppData\\Local\\Temp\\ipykernel_19116\\3842782351.py:22: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = es_client.search(index=index_name, body=search_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = elastic_search(\n",
    "    query=\"When is the next cohort?\",\n",
    "    index_name=\"documents_20240820_123728\"\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f7ecf-7b74-4f7a-ad6b-648c0aa3f48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
