## Домашнє завдання: Оцінка та моніторинг

У цьому домашньому завданні ми оцінюватимемо якість нашої системи RAG.

> Можливо, ваші відповіді не будуть точно співпадати. Якщо це так, виберіть найближчу.
Рішення:

* Відео: TBA
* Нотатник: TBA

## Отримання даних

Почнемо з отримання набору даних. Ми використаємо дані, які ми згенерували в модулі.

Зокрема, ми оцінюватимемо якість нашої системи RAG
за допомогою [gpt-4o-mini](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv)

Прочитайте його:

```python
url = f'{github_url}?raw=1'
df = pd.read_csv(url)
```

Ми будемо використовувати лише перші 300 документів:

```python
df = df.iloc[:300]
```

## Питання 1. Отримання моделі векторних представлень

Тепер отримайте модель векторних представлень `multi-qa-mpnet-base-dot-v1` з
[бібліотеки Sentence Transformer](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)

> Примітка: це не та ж модель, що в домашньому завданні 3
```bash
from sentence_transformers import SentenceTransformer
embedding_model = SentenceTransformer(model_name)
```

Створіть векторні представлення для першої відповіді LLM:

```python
answer_llm = df.iloc[0].answer_llm
```

Яке перше значення отриманого вектора?

* -0.42
* -0.22
* -0.02
* 0.21

- Q1: First value of the resulting vector: -0.42

## Питання 2. Обчислення скалярного добутку

Тепер для кожної пари відповідей створимо векторні представлення та обчислимо скалярний добуток між ними

Ми розмістимо результати (оцінки) у списку `evaluations`

Який 75-й перцентиль оцінок?

* 21.67
* 31.67
* 41.67
* 51.67

- Q2: 75th percentile of the dot product scores: 31.67

## Питання 3. Обчислення косинуса

З питання 2 ми бачимо, що результати не знаходяться в діапазоні [0, 1]. Це тому, що вектори, отримані з цієї моделі, не нормалізовані.

Тому нам потрібно їх нормалізувати.

Для цього ми

* Обчислимо норму вектора
* Поділимо кожен елемент на цю норму

Отже, для вектора `v`, це буде `v / ||v||`

У numpy це робиться так:

```python
norm = np.sqrt((v * v).sum())
v_norm = v / norm
```

Давайте вставимо це у функцію, а потім обчислимо скалярний добуток 
між нормалізованими векторами. Це дасть нам косинусну схожість.

Який 75-й перцентиль косинусної схожості в оцінках?

* 0.63
* 0.73
* 0.83
* 0.93

- Q3: 75th percentile of the cosine similarities: 0.84

## Питання 4. ROUGE

Тепер ми розглянемо альтернативну метрику - оцінку ROUGE.  

Це набір метрик, який порівнює дві відповіді на основі збігу n-грам, послідовностей слів та пар слів.

Вона може дати більш детальну оцінку схожості текстів, ніж просто косинусна схожість.

Нам не потрібно реалізовувати це самостійно, є python-пакет для цього:

```bash
pip install rouge
```

(Остання версія на момент написання - `1.0.1`)

Давайте обчислимо оцінку ROUGE між відповідями на індексі 10 нашого датафрейму (`doc_id=5170565b`)

```
from rouge import Rouge
rouge_scorer = Rouge()
scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]
```

Існують три оцінки: `rouge-1`, `rouge-2` та `rouge-l`, і точність, повнота та F1 оцінка для кожної з них.

* `rouge-1` - збіг уніграмів,
* `rouge-2` - біграмів,
* `rouge-l` - найдовша спільна підпослідовність

Яка F оцінка для `rouge-1`?

- 0.35
- 0.45
- 0.55
- 0.65

- Q4: f1 score for `rouge-1`: 0.45

## Питання 5. Середня оцінка ROUGE

Давайте обчислимо середнє значення між `rouge-1`, `rouge-2` та `rouge-l` для того ж запису з питання 4

- 0.35
- 0.45
- 0.55
- 0.65

- Q5: Average ROUGE score for the record: 0.35

## Питання 6. Середня оцінка ROUGE для всіх точок даних

Тепер давайте обчислимо оцінку для всіх записів

```python
rouge_1 = scores['rouge-1']['f']
rouge_2 = scores['rouge-2']['f']
rouge_l = scores['rouge-l']['f']
rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3
```

І створимо з них датафрейм

Яке середнє значення `rouge_2` серед усіх записів?

- 0.10
- 0.20
- 0.30
- 0.40

- Q6: Average "rouge_2" score across all records: 0.21