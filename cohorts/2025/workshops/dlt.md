# Open source data ingestion for RAGs with dlt

* Sign up here: https://lu.ma/kdp6ex5s (optional)
* Video: TBA
* Homework solution: TBA

​In this hands-on workshop, we’ll build an end-to-end data pipeline using the REST API as a source. You'll learn how to use dlt to ingest fresh data into database, and how to index it in Cognee for powerful semantic querying.

​We'll also explore challenges in handling evolving relationships between resources and experiment with solutions for capturing those changes more intelligently over time.

​​We'll cover the following steps:


* ​Extract and normalize data from REST APIs using `dlt`
* ​Load structured data into a database
* ​Index and query the data semantically using Cognee
* ​Handle time-sensitive and incremental updates across related resources

​By the end of this session, you'll know how to build an intelligent ingestion pipeline that stays in sync with dynamic data sources and powers semantic applications using open-source tools.

# Resources

* TBA

--- 

# Homework

TBA

## Submit the results

* Submit your results here: https://courses.datatalks.club/llm-zoomcamp-2025/homework/dlt
* It's possible that your answers won't match exactly. If it's the case, select the closest one.
