{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53dd41a-03a8-49eb-b087-9b094158d2dd",
   "metadata": {},
   "source": [
    "# Homework: Open-Source LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a61c40-24a2-46e6-b0e6-c67cacf4c2f3",
   "metadata": {},
   "source": [
    "In this homework, we'll experiment more with Ollama\n",
    "| \n",
    "\n",
    "    It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "## Q1. Running Ollama with Docker\n",
    "\n",
    "-----\n",
    "Let's run ollama with Docker. We will need to execute the same command as in the lectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b85f2-a349-49ac-804d-e289443d3439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'ollama/ollama:latest' locally\n",
      "latest: Pulling from ollama/ollama\n",
      "\n",
      "\u001b[1Bc8da3324: Pulling fs layer \n",
      "\u001b[1B0ab4fb75: Pulling fs layer \n",
      "\u001b[1B7d737fbb: Pull complete 7.6MB/387.6MBB\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:4a3c5b5261f325580d7f4f6440e5094d807784f0513439dcabfda9c2bdf4191e\n",
      "Status: Downloaded newer image for ollama/ollama:latest\n",
      "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
      "Your new public key is: \n",
      "\n",
      "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPRZaCnmYa0SCjXptUo46THyPHaZEnkucctNEB1o5CMn\n",
      "\n",
      "2024/07/02 18:53:33 routes.go:1064: INFO server config env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: OLLAMA_DEBUG:false OLLAMA_FLASH_ATTENTION:false OLLAMA_HOST:http://0.0.0.0:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE: OLLAMA_LLM_LIBRARY: OLLAMA_MAX_LOADED_MODELS:1 OLLAMA_MAX_QUEUE:512 OLLAMA_MAX_VRAM:0 OLLAMA_MODELS:/root/.ollama/models OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:1 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://*] OLLAMA_RUNNERS_DIR: OLLAMA_SCHED_SPREAD:false OLLAMA_TMPDIR: ROCR_VISIBLE_DEVICES:]\"\n",
      "time=2024-07-02T18:53:33.096Z level=INFO source=images.go:730 msg=\"total blobs: 0\"\n",
      "time=2024-07-02T18:53:33.097Z level=INFO source=images.go:737 msg=\"total unused blobs removed: 0\"\n",
      "time=2024-07-02T18:53:33.097Z level=INFO source=routes.go:1111 msg=\"Listening on [::]:11434 (version 0.1.48)\"\n",
      "time=2024-07-02T18:53:33.098Z level=INFO source=payload.go:30 msg=\"extracting embedded files\" dir=/tmp/ollama1989669701/runners\n",
      "time=2024-07-02T18:53:36.566Z level=INFO source=payload.go:44 msg=\"Dynamic LLM libraries [cpu_avx cpu_avx2 cuda_v11 rocm_v60101 cpu]\"\n",
      "time=2024-07-02T18:53:36.568Z level=INFO source=types.go:98 msg=\"inference compute\" id=0 library=cpu compute=\"\" driver=0.0 name=\"\" total=\"15.6 GiB\" available=\"12.6 GiB\"\n"
     ]
    }
   ],
   "source": [
    "!docker run -it \\\n",
    "    --rm \\\n",
    "    -v ollama:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b68e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5af65c1b-de11-428f-9530-79f7d9706076",
   "metadata": {},
   "source": [
    "What's the version of ollama client?\n",
    "\n",
    "To find out, enter the container and execute ollama with the -v flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f839b3c9-f3a6-4697-9573-eb9f873a7047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/llm-zoomcamp/02-open-source'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c558cc3-b2aa-492f-8354-3c28f4755293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21aa9c0-fe82-4ffe-961a-83ca6db09d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 13] Permission denied: '/root/.ollama/models/manifests/registry.ollama.ai/library'\n",
      "/workspaces/llm-zoomcamp/02-open-source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "cd /root/.ollama/models/manifests/registry.ollama.ai/library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee0511-91b8-4318-ad6a-3b2499030e2f",
   "metadata": {},
   "source": [
    "## Q2. Downloading an LLM\n",
    "\n",
    "--------\n",
    "\n",
    "We will donwload a smaller LLM - gemma:2b.\n",
    "\n",
    "Again let's enter the container and pull the model:\n",
    "\n",
    "``ollama pull gemma:2b``\n",
    "\n",
    "In docker, it saved the results into ``/root/.ollama``\n",
    "\n",
    "We're interested in the metadata about this model. You can find it in`` models/manifests/registry.ollama.ai/library``\n",
    "\n",
    "What's the content of the file related to gemma?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40719f0-f98f-4c45-949c-09115629371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"schemaVersion\":2,\"mediaType\":\"application/vnd.docker.distribution.manifest.v2+json\",\"config\":{\"mediaType\":\"application/vnd.docker.container.image.v1+json\",\"digest\":\"sha256:887433b89a901c156f7e6944442f3c9e57f3c55d6ed52042cbb7303aea994290\",\"size\":483},\"layers\":[{\"mediaType\":\"application/vnd.ollama.image.model\",\"digest\":\"sha256:c1864a5eb19305c40519da12cc543519e48a0697ecd30e15d5ac228644957d12\",\"size\":1678447520},{\"mediaType\":\"application/vnd.ollama.image.license\",\"digest\":\"sha256:097a36493f718248845233af1d3fefe7a303f864fae13bc31a3a9704229378ca\",\"size\":8433},{\"mediaType\":\"application/vnd.ollama.image.template\",\"digest\":\"sha256:109037bec39c0becc8221222ae23557559bc594290945a2c4221ab4f303b8871\",\"size\":136},{\"mediaType\":\"application/vnd.ollama.image.params\",\"digest\":\"sha256:22a838ceb7fb22755a3b0ae9b4eadde629d19be1f651f73efb8c6b4e2cd0eea0\",\"size\":84}]}"
     ]
    }
   ],
   "source": [
    "!docker exec -it ollama bash -c \"cat /root/.ollama/models/manifests/registry.ollama.ai/library/gemma/2b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a8696-9a3a-4127-9cc9-2e8eccd06d0b",
   "metadata": {},
   "source": [
    "## Q3. Running the LLM\n",
    "--------\n",
    "Test the following prompt: \"10 * 10\". What's the answer?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80cf9d1-63f8-4f23-ba80-9c7b048ddda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "\n",
    "# Set up the OpenAI client\n",
    "openai.api_base = \"http://localhost:11434/v1\"\n",
    "openai.api_key = \"your-api-key\"  # Replace with your actual API key if needed\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f02fe5-b9a3-4c1e-8e6b-dbb649c1d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab91a840-6488-4f59-b7a6-6ecf6b5af97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"10 * 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1027c68-080b-475b-bd88-bcb79634ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 100.\n",
      "\n",
      "10 * 10 = 100.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdea847e-169f-4814-a958-f58a7dd3f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unknown command \"eval\" for \"ollama\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98caf5cf-230e-4539-8534-27e38e543a73",
   "metadata": {},
   "source": [
    "## Q4. Donwloading the weights\n",
    "------\n",
    "\n",
    "We don't want to pull the weights every time we run a docker container. Let's do it once and have them available every time we start a container.\n",
    "\n",
    "First, we will need to change how we run the container.\n",
    "\n",
    "Instead of mapping the ``/root/.ollama`` folder to a named volume, let's map it to a local directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a5507ad-ffa9-4951-b7c8-ce805be1c375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ollama_files’: File exists\n",
      "docker: Error response from daemon: Conflict. The container name \"/ollama\" is already in use by container \"99f8781b3e0f0e65f9f3f7875f7faf5631acf542541e3660317f149346d442d1\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ollama_files\n",
    "\n",
    "!docker run -it \\\n",
    "    --rm \\\n",
    "    -v ./ollama_files:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58263401-b847-4a7b-9de9-2a2452d28252",
   "metadata": {},
   "source": [
    "Now pull the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df903764-6343-4d37-a059-90f7dc551f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it ollama ollama pull gemma:2b #  in terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f15746-3e1e-428c-b353-699c1119ed82",
   "metadata": {},
   "source": [
    "What's the size of the ``ollama_files/models`` folder?\n",
    "\n",
    " *   0.6G\n",
    " *  1.2G\n",
    " *  1.7G\n",
    " *  2.2G\n",
    "\n",
    "Hint: on linux, you can use du -h for that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c0805e-e736-4508-9717-dc9edd5c7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\t./ollama_files/models/blobs\n",
      "8.0K\t./ollama_files/models/manifests/registry.ollama.ai/library/gemma\n",
      "12K\t./ollama_files/models/manifests/registry.ollama.ai/library\n",
      "16K\t./ollama_files/models/manifests/registry.ollama.ai\n",
      "20K\t./ollama_files/models/manifests\n",
      "1.6G\t./ollama_files/models\n",
      "1.6G\t./ollama_files\n",
      "40K\t./.ipynb_checkpoints\n",
      "1.6G\t.\n"
     ]
    }
   ],
   "source": [
    "!du -h  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c6710-f120-4d1a-a456-7b9ee3d35daf",
   "metadata": {},
   "source": [
    "What's the size of the ollama_files/models folder?\n",
    "\n",
    " *   0.6G\n",
    " *  1.2G\n",
    " *  1.7G\n",
    " *  2.2G\n",
    "\n",
    "Hint: on linux, you can use du -h for that.\n",
    "\n",
    "## Q5. Adding the weights\n",
    "-----\n",
    "Let's now stop the container and add the weights to a new image\n",
    "\n",
    "For that, let's create a ``Dockerfile:``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff91d51-d6a7-47fb-ac46-1f9463ddbd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52e4f134-0c19-4391-a906-f5c099aa6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt},\n",
    "                 ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    print(\"Response:\", response)\n",
    "    print(\"Response:\", response.choices[0].message.content)\n",
    "    print(\"Completion Tokens:\", response.usage.completion_tokens)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b62ed69f-a775-499b-8306-7e09929c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the formula for energy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4fe65dc7-61ad-4670-a111-dc8433a3bf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: ChatCompletion(id='chatcmpl-270', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Sure, here's the formula for energy:\\n\\n**E = K + U**\\n\\nWhere:\\n\\n* **E** is the energy in joules (J)\\n* **K** is the kinetic energy in joules (J)\\n* **U** is the potential energy in joules (J)\\n\\n**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\\n\\n**K = 1/2 * m * v^2**\\n\\n**Potential energy (U)** is the energy an object possesses when it is in a position or has a specific configuration. It is calculated as the product of an object's mass and the gravitational constant (g) multiplied by the height or distance of the object from a reference point.\\n\\n**Gravitational potential energy (U)** is given by the formula:\\n\\n**U = mgh**\\n\\nWhere:\\n\\n* **m** is the mass of the object in kilograms (kg)\\n* **g** is the acceleration due to gravity in meters per second squared (m/s^2)\\n* **h** is the height or distance of the object in meters (m)\\n\\nThe formula for energy can be used to calculate the total energy of an object, the energy of a specific part of an object, or the change in energy of an object over time.\", role='assistant', function_call=None, tool_calls=None))], created=1720001360, model='gemma:2b', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=304, prompt_tokens=0, total_tokens=304))\n",
      "Response: Sure, here's the formula for energy:\n",
      "\n",
      "**E = K + U**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **E** is the energy in joules (J)\n",
      "* **K** is the kinetic energy in joules (J)\n",
      "* **U** is the potential energy in joules (J)\n",
      "\n",
      "**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\n",
      "\n",
      "**K = 1/2 * m * v^2**\n",
      "\n",
      "**Potential energy (U)** is the energy an object possesses when it is in a position or has a specific configuration. It is calculated as the product of an object's mass and the gravitational constant (g) multiplied by the height or distance of the object from a reference point.\n",
      "\n",
      "**Gravitational potential energy (U)** is given by the formula:\n",
      "\n",
      "**U = mgh**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **m** is the mass of the object in kilograms (kg)\n",
      "* **g** is the acceleration due to gravity in meters per second squared (m/s^2)\n",
      "* **h** is the height or distance of the object in meters (m)\n",
      "\n",
      "The formula for energy can be used to calculate the total energy of an object, the energy of a specific part of an object, or the change in energy of an object over time.\n",
      "Completion Tokens: 304\n"
     ]
    }
   ],
   "source": [
    "output = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795267b-d9db-4c25-8655-17eae7e20805",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d99446-4571-415f-b72c-40c49b6b41e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
